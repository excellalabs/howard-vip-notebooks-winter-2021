{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cb316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b32973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, sys,sagemaker                             \n",
    "import pandas as pd   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# plt.xticks(rotation=70)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d816fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket_name = 'howardvip-clinical-data'\n",
    "def table(table_name, nrows=0):\n",
    "    data_path = 's3://{}/{}'.format(bucket_name, 'NOTEEVENTS.csv.gz')\n",
    "    if not nrows:\n",
    "        return pd.read_csv(data_path)\n",
    "    return pd.read_csv(data_path, nrows=nrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ea90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = table('NOTEEVENTS.csv.gz',nrows=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7259efca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b944c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText = df.loc[:,[\"TEXT\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText[\"TEXT\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b35ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['no_contract'] = dfText['TEXT'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afbf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText[\"TEXT\"] = [' '.join(map(str, l)) for l in  dfText['no_contract']]\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b85cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "dfText['tokenized'] = dfText['TEXT'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe589352",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab358b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['TEXT'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['lower'] =dfText['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82af841",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation\n",
    "dfText['no_punc'] = dfText['lower'].apply(lambda x: [word for word in x if word not in punc and word.isalpha()])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fccb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "dfText['stopwords_removed'] = dfText['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f23506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "dfText['pos_tags'] = dfText['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbedcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "dfText['wordnet_pos'] = dfText['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7d6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "dfText['lemmatized'] = dfText['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf5da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText.to_csv('TEXT_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c9035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText.to_csv('cleanedText.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e05b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['lemmatized'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc317ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['TEXT'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20152d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd692ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "w2v_model = Word2Vec(dfText['lemmatized'], vector_size=100, min_count=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df400e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e191e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['doctor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8726eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad81c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('modelwv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092318a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Word2Vec.load('modelwv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e7a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.wv.most_similar(['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8bf2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['tokenizedSent'] = dfText['TEXT'].apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc630671",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['lower1'] =dfText['tokenizedSent'].apply(lambda x: [[word.lower() for word in sent] for sent in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedee45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation\n",
    "dfText['no_punc1'] = dfText['lower1'].apply(lambda x: [[word for word in sent if word not in punc and word.isalpha()] for sent in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26db3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['stopwords_removed1'] = dfText['no_punc1'].apply(lambda x: [[word for word in sent if word not in stop_words]for sent in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97b573",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['pos_tags1'] = dfText['stopwords_removed1'].apply(lambda x: [[nltk.tag.pos_tag(sent)]for sent in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4294b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "dfText['wordnet_pos1'] = dfText['pos_tags1'].apply(lambda x: [[(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in sent]for sent in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c02ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['lemmatized1'] = dfText['wordnet_pos1'].apply(lambda x: [[wnl.lemmatize(word, tag) for word, tag in sent] for sent in x])\n",
    "dfText.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
