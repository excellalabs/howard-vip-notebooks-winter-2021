{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3280e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install contractions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3, sys,sagemaker                             \n",
    "import pandas as pd   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "# import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# plt.xticks(rotation=70)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8d4171",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket_name = 'howardvip-clinical-data'\n",
    "def table(table_name, nrows=0):\n",
    "    data_path = 's3://{}/{}'.format(bucket_name, 'NOTEEVENTS.csv.gz')\n",
    "    if not nrows:\n",
    "        return pd.read_csv(data_path)\n",
    "    return pd.read_csv(data_path, nrows=nrows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cf164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = table('NOTEEVENTS.csv.gz',nrows=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567115aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText = df.loc[:,[\"TEXT\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b99206",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText[\"TEXT\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e18e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['no_contract'] = dfText['TEXT'].apply(lambda x: [contractions.fix(word) for word in x.split()])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af551389",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText[\"TEXT\"] = [' '.join(map(str, l)) for l in  dfText['no_contract']]\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec153c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "dfText['tokenized'] = dfText['TEXT'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b1c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90427c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['TEXT'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['lower'] =dfText['tokenized'].apply(lambda x: [word.lower() for word in x])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7901957",
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = string.punctuation\n",
    "dfText['no_punc'] = dfText['lower'].apply(lambda x: [word for word in x if word not in punc and word.isalpha()])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e21517",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "dfText['stopwords_removed'] = dfText['no_punc'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc5c831",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "dfText['pos_tags'] = dfText['stopwords_removed'].apply(nltk.tag.pos_tag)\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b69634",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "dfText['wordnet_pos'] = dfText['pos_tags'].apply(lambda x: [(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in x])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e73c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "dfText['lemmatized'] = dfText['wordnet_pos'].apply(lambda x: [wnl.lemmatize(word, tag) for word, tag in x])\n",
    "dfText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e95a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText.to_csv('TEXT_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c53f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText.to_csv('cleanedText.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f684810a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea68f355",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['lemmatized'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624a4c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfText['TEXT'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb185c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "w2v_model = Word2Vec(dfText['lemmatized'], vector_size=100, min_count=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a408c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7362e472",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['doctor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96e8c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.wv.most_similar(['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258c0b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('modelwv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e9c87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ec8db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b7636",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d073c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "model1 = Word2Vec.load('modelwv')\n",
    "model2 = Word2Vec.load('w2vec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f95e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.most_similar(['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7818d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.most_similar(['heart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.most_similar(['heart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebba627",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.most_similar(['allergy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0418c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.most_similar(['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f080b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.most_similar(['leukemia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c25361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.most_similar(['leukemia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7766e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.wv.most_similar(['physician'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7d22e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.wv.most_similar(['physician'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors1 = model1.wv\n",
    "word_vectors2 = model2.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8a681a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors1.save(\"word2vec.wordvectors1\")\n",
    "word_vectors2.save(\"word2vec.wordvectors2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39393af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv1 = KeyedVectors.load(\"word2vec.wordvectors1\", mmap='r')\n",
    "wv2 = KeyedVectors.load(\"word2vec.wordvectors2\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff4a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv1[\"patient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0969389",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv2[\"patient\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb2eecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv1.most_similar(positive=['patient', 'list(w2.key_to_index.keys())[-25:])'], negative=['sick'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv1.most_similar(positive=['pressure', \"depression\"], negative=[\"drug\", \"medicine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff22c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv2.most_similar(positive=['pressure', \"depression\"], negative=[\"drug\", \"medicine\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042fda78",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(wv1.key_to_index.keys())[:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22f5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sentenceRowClean.csv', index_col=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4bf87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['lemmatized'].tolist()\n",
    "sentences = []\n",
    "m = \"\"\n",
    "for row in y:\n",
    "    seen = False\n",
    "    for i in row:\n",
    "        if i == \"[\":\n",
    "             seen = True\n",
    "        elif i == \"]\":\n",
    "            sentences.append(m.split(\",\"))\n",
    "            m = \"\"\n",
    "            seen = False\n",
    "        elif seen and i !=\"'\" and i != \"]\" and i != \"[\" and i !=\" \":\n",
    "            m += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec287b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532e23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8305cfdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "w2v_model2 = Word2Vec(sentences, vector_size=100, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87052d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model2.wv.most_similar(['physician'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae6c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model2.wv.most_similar(['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca786c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def sent_vectorizer(sent, model):\n",
    "    sent_vec =[]\n",
    "    numw = 0\n",
    "    for w in sent:\n",
    "        try:\n",
    "            if numw == 0:\n",
    "                sent_vec = model.wv[w]\n",
    "            else:\n",
    "                sent_vec = np.add(sent_vec, model.wv[w])\n",
    "            numw+=1\n",
    "        except:\n",
    "            pass\n",
    "     \n",
    "    return np.asarray(sent_vec) / numw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f086b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for sentence in sentences:\n",
    "    m = (sent_vectorizer(sentence, w2v_model2))\n",
    "    if len(m) > 0:\n",
    "        X.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802e1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (model1.wv[model1.wv.key_to_index])\n",
    "# print (model.similarity('post', 'book'))\n",
    "# print (model.most_similar(positive=['machine'], negative=[], topn=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1511e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c12aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = cluster.KMeans(n_clusters=2)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "silhouette_score = metrics.silhouette_score(X, labels, metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffe7a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.cluster import KMeansClusterer\n",
    "NUM_CLUSTERS=2\n",
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "assigned_clusters = kclusterer.cluster(X[:5000], assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    " \n",
    "model = TSNE(n_components=2, random_state=0)\n",
    "np.set_printoptions(suppress=True)\n",
    " \n",
    "Y=model.fit_transform(X[:5000])\n",
    " \n",
    "plt.scatter(Y[:, 0], Y[:, 1], c=assigned_clusters, s=290,alpha=.5)\n",
    "for j in range(5000):    \n",
    "#    plt.annotate(assigned_clusters[j],xy=(Y[j][0], Y[j][1]),xytext=(0,0),textcoords='offset points')\n",
    "   print (\"%s %s\" % (assigned_clusters[j],  sentences[j]))\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9466296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(model):\n",
    "    labels = []\n",
    "    tokens = []\n",
    "\n",
    "    for word in model.wv.key_to_index:\n",
    "        tokens.append(model.wv[word])\n",
    "        labels.append(word)\n",
    "    \n",
    "    tsne_model = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, random_state=23)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "        \n",
    "    plt.figure(figsize=(16, 16)) \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i],y[i])\n",
    "        plt.annotate(labels[i],\n",
    "                     xy=(x[i], y[i]),\n",
    "                     xytext=(5, 2),\n",
    "                     textcoords='offset points',\n",
    "                     ha='right',\n",
    "                     va='bottom')\n",
    "    plt.show()\n",
    "tsne_plot(w2v_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11d1947",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assigned_clusters)\n",
    "\n",
    "for j in range(len(sentences)):    \n",
    "   plt.annotate(assigned_clusters[j],xy=(Y[j][0], Y[j][1]),xytext=(0,0),textcoords='offset points')\n",
    "   print (assigned_clusters[j],  sentences[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8ab854",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d795ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3ecab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
