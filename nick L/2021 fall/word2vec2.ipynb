{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a720d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d26f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3, sys,sagemaker                             \n",
    "import pandas as pd   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# plt.xticks(rotation=70)\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9054e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleanedText.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5201ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['no_punc'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffcd923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = df.loc[:,['TEXT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9875a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "table['tokenizedSent'] = table['TEXT'].apply(sent_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3a442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "table['tokenizedSent'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "table['tokenized_words'] = table['tokenizedSent'].apply(lambda x: [word_tokenize(sent) for sent in x])\n",
    "# punc = string.punctuation\n",
    "# table['no_punc/numbers'] = table['tokenizedSent'].apply(lambda x: [word.lower() for word in x if word not in punc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ad2234",
   "metadata": {},
   "outputs": [],
   "source": [
    "table['tokenized_words'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aca44a",
   "metadata": {},
   "outputs": [],
   "source": [
    " table['no_punc/numbers'] = table['tokenized_words'].apply(lambda x: [[word.lower() for word in sent if word not in punc and word.isalpha()] for sent in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e6701",
   "metadata": {},
   "outputs": [],
   "source": [
    " table['no_punc/numbers'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a114cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "table['stopwords_removed'] = table['no_punc/numbers'].apply(lambda x: [[word for word in sent if word not in stop_words]for sent in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ce365",
   "metadata": {},
   "outputs": [],
   "source": [
    "table['stopwords_removed'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475a6fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "table['pos_tags'] = table['stopwords_removed'].apply(lambda x: [nltk.tag.pos_tag(sent) for sent in x if len(sent)> 0 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fdf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "table['pos_tags'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13410946",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "table['wordnet_pos'] = table['pos_tags'].apply(lambda x: [[(word, get_wordnet_pos(pos_tag)) for (word, pos_tag) in sent]for sent in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a25dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "table['wordnet_pos'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fce81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "table['lemmatized'] = table['wordnet_pos'].apply(lambda x: [[wnl.lemmatize(word, tag) for word, tag in sent] for sent in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0273c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.to_csv('sentenceRowClean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08cc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a8b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "w2v_model2 = Word2Vec(table['lemmatized'], vector_size=100, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9a5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = list(table['lemmatized'])\n",
    "sentences = []\n",
    "for row in y:\n",
    "    for sent in row:\n",
    "        sentences.append(sent)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa627fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "w2v_model2 = Word2Vec(sentences, vector_size=100, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95f91d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model2.wv.most_similar(['disease'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6af8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model2.wv.most_similar(['cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7365ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model2.save('w2vec2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c1a83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18847756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
